{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook Steps Through Prep-Processing and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Relevant Libraries, Repo Functions/Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import lstsq\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# From Repo\n",
    "from queries.db_queries import *\n",
    "from functions.running_avg import *\n",
    "from functions.helper_functions import *\n",
    "from configs.definitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data: Team's W/L records, Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_teams = sql_query(curr_teams_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path_2023 = 'C:/Users/conor/Downloads/gl2023/gl2023.txt'\n",
    "log_path_2022 = 'C:/Users/conor/Downloads/gl2022/gl2022.txt'\n",
    "\n",
    "gamelogs_2022 = pd.read_csv(log_path_2022, header=None)\n",
    "gamelogs_2023 = pd.read_csv(log_path_2023, header=None)\n",
    "gamelogs_2022_2023 = pd.concat([gamelogs_2022, gamelogs_2023])\n",
    "gamelogs = pd.concat([gamelogs_2022_2023.iloc[:,:13], gamelogs_2022_2023.iloc[:,16:19],gamelogs_2022_2023.iloc[:,102], gamelogs_2022_2023.iloc[:,104]], axis = 1)\n",
    "gamelogs = gamelogs.set_axis(game_log_column_headers, axis = 1)\n",
    "\n",
    "#Fix Abbreviations\n",
    "gamelogs['Visiting Team'] = gamelogs['Visiting Team'].replace(renamed_team)\n",
    "gamelogs['Home Team'] = gamelogs['Home Team'].replace(renamed_team)\n",
    "\n",
    "gamelogs['Date'] = pd.to_datetime(gamelogs['Date'], format = '%Y%m%d')\n",
    "\n",
    "time_window=6 #6 Games for running avergage calculations\n",
    "running_avg_df = get_running_avg(gamelogs_=gamelogs, timeframe=time_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess a \"Difficulty Score\" for each game from the Starting Pitcher's persepctive, based on opponents ability to score runs (overall and as of late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Difficulty_Score_Home = []\n",
    "Difficulty_Score_Away = []\n",
    "for idx, game in gamelogs.iterrows(): #Loop through the boxscores\n",
    "    date = game['Date']\n",
    "    home_chllg_run = running_avg_df[(running_avg_df['Date']== date) & (running_avg_df['Visiting Team'] == game['Visiting Team'])]['VTRA_S'].values\n",
    "    home_chllg_overall = running_avg_df[(running_avg_df['Date']== date) & (running_avg_df['Visiting Team'] == game['Visiting Team'])]['VTA_S'].values\n",
    "    Difficulty_Score_Home.append(np.average([home_chllg_run,home_chllg_overall], weights= [2,1], axis=0)[0] if len(home_chllg_overall) > 0 else None)\n",
    "\n",
    "    vis_chllg_run = running_avg_df[(running_avg_df['Date']== date) & (running_avg_df['Home Team'] == game['Home Team'])]['HTRA_S'].values\n",
    "    vis_chllg_overall = running_avg_df[(running_avg_df['Date']== date) & (running_avg_df['Home Team'] == game['Home Team'])]['HTA_S'].values\n",
    "    Difficulty_Score_Away.append(np.average([vis_chllg_run,vis_chllg_overall], weights= [2,1], axis=0)[0] if len(vis_chllg_overall) > 0 else None)\n",
    "\n",
    "gamelogs['Home Challenge'] = Difficulty_Score_Home\n",
    "gamelogs['Visiting Challenge'] = Difficulty_Score_Away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Philadelphia Phillies to Explore visulaizations of this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phils = gamelogs[(gamelogs['Visiting Team'] == 'PHI') | (gamelogs['Home Team'] == 'PHI')]\n",
    "phils = phils.reset_index(drop=True)\n",
    "for idx, game in phils.iterrows(): #Remove first 5 games of each season\n",
    "    if game['Visiting Team'] == 'PHI':\n",
    "        if game['Visiting Team Game Number'] < time_window:\n",
    "            phils = phils.drop(index = idx)\n",
    "    else:\n",
    "         if game['Home Team Game Number'] < time_window:\n",
    "            phils = phils.drop(index = idx)       \n",
    "\n",
    "phils = phils.reset_index(drop=True)\n",
    "\n",
    "phils['Outcome'] = np.where(\n",
    "    (phils['Home Team'] == 'PHI') & (phils['Home Team Score'] > phils['Visiting Team Score']) | \n",
    "    (phils['Visiting Team'] == 'PHI') & (phils['Visiting Team Score'] > phils['Home Team Score']),\n",
    "    'win', \n",
    "    'loss'\n",
    ")\n",
    "phils['Opponent'] = np.where( (phils['Home Team'] == 'PHI'), phils['Visiting Team'],phils['Home Team'])\n",
    "colors = np.where(phils['Outcome'] == 'win', 'green', 'red').tolist() # \n",
    "\n",
    "phils['Challenge Score'] = np.where(phils['Home Team'] == 'PHI', phils['Home Challenge'], phils['Visiting Challenge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(phils['Challenge Score'].index, phils['Challenge Score'], c=colors, marker='o', edgecolor='black', s=40, cmap='coolwarm')\n",
    "plt.title('Phillies Game Difficulty', fontsize=20, fontweight='bold')\n",
    "plt.xlabel('Game Index', fontsize=14,fontweight='bold')\n",
    "plt.ylabel('Score', fontsize=14,fontweight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Adding a color legend\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Win', markerfacecolor='green', markersize=10),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Loss', markerfacecolor='red', markersize=10)]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Adding mean line for reference\n",
    "mean = phils['Challenge Score'].mean()\n",
    "plt.axhline(mean, color='gray', linestyle='dashed', linewidth=1)\n",
    "plt.text(25, mean + 0.12, f'Mean: {mean:.2f}', color='gray', ha='right')\n",
    "\n",
    "temp_df = avoid_overlap(phils[((phils['Challenge Score'] > 6.75)|(phils['Challenge Score'] < 2.75) )])\n",
    "for i, row in temp_df.iterrows():\n",
    "    if row['Home Team'] == 'PHI':\n",
    "        plt.text(\n",
    "            x=i - 8,\n",
    "            y=row['Challenge Score'] + 0.1,\n",
    "            s=row['Home SP'],\n",
    "            ha='left',\n",
    "            weight='bold',\n",
    "            fontsize=6\n",
    "        )\n",
    "    elif row[\"Visiting Team\"] == 'PHI':\n",
    "          plt.text(\n",
    "            x=i - 8,\n",
    "            y=row['Challenge Score'] + 0.1,\n",
    "            s=row['Visiting SP'],\n",
    "            ha='left',\n",
    "            weight='bold',\n",
    "            fontsize=6\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(phils['Challenge Score'][ (phils['Outcome']== 'loss')], edgecolor='black', alpha = 0.65, color='red', label='losses')\n",
    "plt.hist(phils['Challenge Score'][ (phils['Outcome']== 'win')], edgecolor='black', alpha = 0.8, color='green', label = 'wins')\n",
    "plt.xlabel('Score', fontsize=12,fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=12,fontweight='bold')\n",
    "#plt.title('Score Histogram', fontsize=16,fontweight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.legend(loc='center right')\n",
    "loss_mean = np.mean(phils['Challenge Score'][ (phils['Outcome']== 'loss')])\n",
    "win_mean = np.mean(phils['Challenge Score'][(phils['Outcome']== 'win')])\n",
    "\n",
    "# Add mean line\n",
    "plt.axvline(loss_mean, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.text(loss_mean + 0.2, plt.ylim()[1]*0.94, f'Mean Loss Score: {loss_mean:.2f}', color='red')\n",
    "plt.axvline(win_mean, color='green', linestyle='dashed', linewidth=1)\n",
    "plt.text(win_mean - 2.2, plt.ylim()[1]*0.94, f'Mean Win Score: {win_mean:.2f}', color='green')\n",
    "plt.title('2022/2023 Phillies Season', fontweight='bold', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess IQR Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = phils['Challenge Score'].quantile(0.25)\n",
    "q3 = phils['Challenge Score'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "tough_games = phils[(phils['Challenge Score'] >= q3 + 1.5*iqr) ]\n",
    "easy_games = phils[(phils['Challenge Score'] <= q1 - 1.5*iqr) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_std = np.std(phils['Challenge Score'])\n",
    "tough_games = phils[(phils['Challenge Score'] >= mean + 2*score_std)]\n",
    "easy_games = phils[(phils['Challenge Score'] <= mean - 2*score_std)]\n",
    "outlier_games = pd.concat([easy_games, tough_games])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine A, b and weights for Weighted Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamelogs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "num_feats = 3\n",
    "num_teams = len(pd.unique(gamelogs[['Home Team', 'Visiting Team']].values.ravel()))\n",
    "A = np.zeros((162*num_teams*2,num_teams*num_feats)) #162 games, 2 seasons\n",
    "b = np.zeros((162*num_teams*2,1))\n",
    "\n",
    "current_teams = current_teams.sort_values(by =['yearid','Team'])\n",
    "current_teams.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "weights = []\n",
    "# Group by 'Home Team' and 'Visiting Team' to calculate the occurrence of each matchup\n",
    "matchup_counts = gamelogs.groupby(['Home Team', 'Visiting Team']).size().reset_index(name='Count')\n",
    "\n",
    "# Iterate over the grouped matchups\n",
    "for (home_team, visiting_team), group in gamelogs.groupby(['Home Team', 'Visiting Team']):\n",
    "    home_team_idx = current_teams.index[(current_teams['Team'] == home_team) & (current_teams['yearid'] == 2022)] #Year Doesn't matter, pick one as long as it exists in df\n",
    "    visiting_team_idx = current_teams.index[(current_teams['Team'] == visiting_team) & (current_teams['yearid'] == 2022)]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        # Set offensive team factor\n",
    "        A[idx, home_team_idx * num_feats] = 1\n",
    "        A[idx + 1, visiting_team_idx * num_feats] = 1\n",
    "\n",
    "        # Set defensive team factor\n",
    "        A[idx, visiting_team_idx * num_feats + 1] = 1\n",
    "        A[idx + 1, home_team_idx * num_feats + 1] = 1\n",
    "\n",
    "        # Set park factor (assuming a specific column index for park factors)\n",
    "        A[idx, home_team_idx * num_feats + 2] = 1  # Adjust this index if park factors are in a different column\n",
    "        A[idx + 1, home_team_idx * num_feats + 2] = 1\n",
    "\n",
    "        b[idx] = row['Home Team Score']\n",
    "        b[idx + 1] = row['Visiting Team Score']\n",
    "        \n",
    "        idx += 2\n",
    "        \n",
    "        weights.append(len(group))\n",
    "        weights.append(len(group))\n",
    "\n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Weighted PF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term to the predictors\n",
    "X = sm.add_constant(A)\n",
    "\n",
    "# Fit the WLS model\n",
    "wls_model = sm.WLS(b, X, weights=weights).fit()\n",
    "beta = wls_model.params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract every third coefficient starting from the first coefficient\n",
    "coefficients = beta[1:]\n",
    "constant = coefficients[0]\n",
    "\n",
    "park_factors = []\n",
    "\n",
    "# Populate the park factor scores\n",
    "for team in current_teams['Team'][0:30]:\n",
    "    park_factor = coefficients[current_teams.index[current_teams['Team'] == team][0] * num_feats + 2]\n",
    "    park_factors.append(park_factor)\n",
    "\n",
    "# Create a new DataFrame with teams and their corresponding park factor scores\n",
    "df_park_factors = pd.DataFrame({\n",
    "    'Team': current_teams['Team'][0:30],\n",
    "    'ParkFactor': park_factors\n",
    "}).sort_values(by='ParkFactor', ascending= False)\n",
    "\n",
    "df_park_factors.reset_index(inplace=True, drop=True)\n",
    "df_park_factors['NormPF'] = min_max_norm(df_park_factors,'ParkFactor')\n",
    "print('Weighted Park Factors')\n",
    "print(round(df_park_factors.sort_values(by='ParkFactor', ascending= False).head(),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Baseball Savant's Park Factor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SavantPF = pd.read_csv('C:/Users/conor/Downloads/BaseballSavantPF2023.csv')\n",
    "SavantPF['NormPF_Savant'] = min_max_norm(SavantPF,'Park Factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JoinPFs = pd.merge(df_park_factors, SavantPF, on='Team')\n",
    "JoinPFs = JoinPFs.drop(columns=['Rank'])\n",
    "JoinPFs['Diff'] = (abs(JoinPFs['NormPF'] - JoinPFs['NormPF_Savant'])*100).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JoinPFs.sort_values(by='Diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JoinPFs['Diff'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting Starting Pitchers ERAs for Difficulty and PF Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPs = sql_query(SP_query) #SPs who threw at least 10 games in 2022 and 2023\n",
    "phils_pitchers = SPs[(SPs['Teams 2022'] == 'PHI') & (SPs['Teams 2023']=='PHI')]\n",
    "#phils_pitchers = sql_query(Phils_SP_query) #Phils Pitchers from 2022/2023 with >= 10 Games Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to collect pitcher data\n",
    "Names = []\n",
    "avg_diffs_2022 = []\n",
    "avg_diffs_2023 = []\n",
    "avg_norm_pf_2022 = []\n",
    "avg_norm_pf_2023 = []\n",
    "\n",
    "# Add \"Challenge Score\" column if it doesn't already exist\n",
    "if 'Challenge Score' not in gamelogs:\n",
    "    gamelogs['Challenge Score'] = np.nan\n",
    "    home_c_indx = gamelogs.shape[1] - 3\n",
    "    vis_c_indx = gamelogs.shape[1] - 2\n",
    "    score_idx = gamelogs.shape[1] -1\n",
    "\n",
    "# Process each pitcher to calculate stats for 2022 and 2023 separately\n",
    "for pitcher in SPs['Full Name']:\n",
    "    pf_2022, pf_2023 = [], []\n",
    "    games_started = gamelogs[(gamelogs['Home SP'] == pitcher) | (gamelogs['Visiting SP'] == pitcher)].reset_index(drop=True)\n",
    "    #games_started = gamelogs[ (gamelogs['Visiting SP'] == pitcher)].reset_index(drop=True)\n",
    "\n",
    "    for idx, game in games_started.iterrows():\n",
    "        # Assign challenge scores based on home/visiting team\n",
    "        if games_started.loc[idx, 'Home SP'] == pitcher:\n",
    "            games_started.iloc[idx, score_idx] = games_started.loc[idx, 'Home Challenge']\n",
    "        elif games_started.loc[idx, 'Visiting SP'] == pitcher:\n",
    "            games_started.iloc[idx, score_idx] = games_started.loc[idx, 'Visiting Challenge']\n",
    "        \n",
    "        # Get park factor based on the home team\n",
    "        park_factor = df_park_factors['NormPF'][df_park_factors['Team'] == game['Home Team']].values\n",
    "        if len(park_factor) > 0:\n",
    "            if game['Date'].year == 2022:\n",
    "                pf_2022.append(park_factor)\n",
    "            elif game['Date'].year == 2023:\n",
    "                pf_2023.append(park_factor)\n",
    "        else:\n",
    "            print('This Park Has Issues: ', game['Home Team'])\n",
    "    \n",
    "    # Calculate averages for 2022\n",
    "    games_2022 = games_started[games_started['Date'].dt.year == 2022]\n",
    "    avg_diff_2022 = np.mean(games_2022['Challenge Score']) if not games_2022.empty else 0\n",
    "    avg_norm_pf_2022.append(round(np.mean(pf_2022), 2) if pf_2022 else 0)\n",
    "\n",
    "    # Calculate averages for 2023\n",
    "    games_2023 = games_started[games_started['Date'].dt.year == 2023]\n",
    "    avg_diff_2023 = np.mean(games_2023['Challenge Score']) if not games_2023.empty else 0\n",
    "    avg_norm_pf_2023.append(round(np.mean(pf_2023), 2) if pf_2023 else 0)\n",
    "\n",
    "    # Append final results\n",
    "    Names.append(pitcher)\n",
    "    avg_diffs_2022.append(round(avg_diff_2022, 2))\n",
    "    avg_diffs_2023.append(round(avg_diff_2023, 2))\n",
    "\n",
    "# Create the final DataFrame with separate columns for 2022 and 2023\n",
    "Pitchers_2023 = pd.DataFrame({\n",
    "    'Name': Names,\n",
    "    'Avg Game Difficulty Score 2022': avg_diffs_2022,\n",
    "    'Avg Game Difficulty Score 2023': avg_diffs_2023,\n",
    "    '2022 ERA': SPs['ERA 2022'],\n",
    "    '2023 ERA': SPs['ERA 2023'],\n",
    "    'PF_Norm 2022': avg_norm_pf_2022,\n",
    "    'PF_Norm 2023': avg_norm_pf_2023,\n",
    "    'ERA Delta': SPs['ERA CHANGE YOY'].astype(np.float32)\n",
    "}).sort_values(by='Avg Game Difficulty Score 2023', ascending=False)\n",
    "\n",
    "Pitchers_2023['PF Delta YOY'] = np.round(Pitchers_2023['PF_Norm 2023'] - Pitchers_2023['PF_Norm 2022'],3)\n",
    "Pitchers_2023['Game Diff Delta YOY'] = np.round(Pitchers_2023['Avg Game Difficulty Score 2023'] - Pitchers_2023['Avg Game Difficulty Score 2022'],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pitchers_2023.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sns.pairplot(Pitchers_2023[['ERA Delta','PF Delta YOY','Game Diff Delta YOY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = Pitchers_2023['ERA Delta'].mean()\n",
    "std = Pitchers_2023['ERA Delta'].std()\n",
    "\n",
    "Predict_Pitchers = Pitchers_2023[(Pitchers_2023['ERA Delta'] >= mean - 1*std) & (Pitchers_2023['ERA Delta'] <= mean +1*std)]\n",
    "Predict_Pitchers =Predict_Pitchers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_Pitchers['ERA Delta'].mean() # Baseball Rules affecting overall ERA measurements\n",
    "Predict_Pitchers['PF Delta Norm'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Predict_Pitchers['2022 ERA Norm'] = scaler.fit_transform(Predict_Pitchers['2022 ERA'].to_numpy().reshape(-1, 1))\n",
    "Predict_Pitchers['2023 ERA Norm'] = scaler.fit_transform((Predict_Pitchers['2023 ERA']- Predict_Pitchers['ERA Delta'].mean()).to_numpy().reshape(-1, 1))\n",
    "#Predict_Pitchers['2023 ERA Norm'] = scaler.fit_transform((Predict_Pitchers['2023 ERA']).to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_Pitchers['PF Delta Norm'] = mean_normalization(Predict_Pitchers, 'PF Delta YOY')\n",
    "Predict_Pitchers['Game Diff Delta Norm'] = mean_normalization(Predict_Pitchers, 'Game Diff Delta YOY')\n",
    "\n",
    "#Predict_Pitchers.reset_index(drop=True, inplace=True)\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test  = train_test_split(Predict_Pitchers[['2022 ERA Norm','PF Delta Norm','Game Diff Delta Norm']],\n",
    "                                                                                  Predict_Pitchers['2023 ERA Norm'],\n",
    "                                                                                  Predict_Pitchers.index, \n",
    "                                                                                  test_size=0.25, random_state=41)\n",
    "X_train = X_train.to_numpy().astype(float)\n",
    "X_test =X_test.to_numpy().astype(float)\n",
    "y_train = y_train.to_numpy().astype(float)\n",
    "y_test = np.round(y_test,3).to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(256, activation=\"tanh\", name=\"Hidden_Layer_1\")(inputs)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"leaky_relu\", name=\"Hidden_Layer_2\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"leaky_relu\", name=\"Hidden_Layer_3\")(x)\n",
    "x = tf.keras.layers.Dense(28, activation=\"leaky_relu\", name=\"Hidden_Layer_4\")(x)\n",
    "outputs = tf.keras.layers.Dense(1, name=\"Output_Layer\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"ERA_Predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "               loss='mse',\n",
    "               metrics= ['mae','mse'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2000, validation_split=0.2, verbose=0, callbacks=[early_stopping])\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values_normal = model.predict(tf.convert_to_tensor(X_test, dtype=tf.float32)).flatten()  # Flatten to ensure compatibility with y_test\n",
    "predicted_values = scaler.inverse_transform(predicted_values_normal.reshape(-1,1))\n",
    "y_test_inverse = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "pitcher_mapping = Predict_Pitchers['Name']\n",
    "\n",
    "# Retrieve the pitcher names for training and testing sets\n",
    "pitchers_train = pitcher_mapping.loc[indices_train]\n",
    "pitchers_test = pitcher_mapping.loc[indices_test]\n",
    "\n",
    "#right_dir = True if \n",
    "\n",
    "# Calculate the error (difference between predicted and actual values)\n",
    "errors = abs(np.round(((predicted_values - y_test_inverse)/y_test_inverse)*100,2)).reshape(-1)\n",
    "\n",
    "# Create a DataFrame with the required data\n",
    "results_df = pd.DataFrame({\n",
    "    '2022 Measured ERA': Predict_Pitchers['2022 ERA'].loc[indices_test].values,\n",
    "    '2023 Measured ERA': y_test_inverse.reshape(-1), # Actual values from y_test\n",
    "    'ERA Delta'         : np.round(Predict_Pitchers['ERA Delta'].loc[indices_test].values - Predict_Pitchers['ERA Delta'].mean(),3),\n",
    "    'Prediction Delta': np.round(predicted_values.reshape(-1) - Predict_Pitchers['2022 ERA'].loc[indices_test].values,3),\n",
    "    '2023 Predicted ERA': predicted_values.reshape(-1),  # Predicted values from the model\n",
    "    'Error (%)': errors,\n",
    "    'Pitcher': pitchers_test.values                  # Difference between predicted and actual values\n",
    "})\n",
    "\n",
    "# Print or inspect the DataFrame\n",
    "results_df.sort_values(by= 'Error (%)', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(results_df[['ERA Delta','Error (%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df[results_df['ERA Delta'] < 5].sort_values(by= 'Error (%)', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df.index, results_df['2022 Measured ERA'], alpha = 0.65, color='gray', label='2022 ERA', marker = 'o')\n",
    "plt.plot(results_df.index, results_df['2023 Measured ERA'],  alpha = 0.9, color='green', label = '2023 ERA', marker = 'o')\n",
    "plt.plot(results_df.index, results_df['2023 Predicted ERA'], alpha = 0.9, color='blue', label = 'Predicted 2023 ERA', marker = 'o')\n",
    "#plt.scatter(results_df.index, results_df['2023 Predicted ERA'], edgecolor='black', alpha = 0.65, color='blue', label='Prediction')\n",
    "plt.xlabel('Picher Index', fontsize=12,fontweight='bold')\n",
    "plt.ylabel('ERA', fontsize=12,fontweight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.legend(loc='upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
